{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8b87abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt \n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c491e6",
   "metadata": {},
   "source": [
    "Part 2.3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cdfc689b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imgprocess(img):\n",
    "    img = img.astype(np.float32)\n",
    "    if img.max() > 1.5: img /= 255.0\n",
    "    return img\n",
    "\n",
    "def samesizer(A, B):  # with interpolation\n",
    "    if A.shape[:2] != B.shape[:2]:\n",
    "        B = cv2.resize(B, (A.shape[1], A.shape[0]), interpolation=cv2.INTER_AREA)\n",
    "    return A, B\n",
    "\n",
    "def gaussianStack(img, levels=5, sigma=2.0):  # not downsampling likle in pyramid\n",
    "    img = imgprocess(img)\n",
    "    G = [img]\n",
    "    for _ in range(1, levels): #apply gaussian filter at each level\n",
    "        G.append(cv2.GaussianBlur(G[-1], (0,0), sigmaX=sigma, sigmaY=sigma,\n",
    "                                  borderType=cv2.BORDER_REFLECT))\n",
    "    return G\n",
    "\n",
    "def laplacianStack(G):\n",
    "    L = [G[i] - G[i+1] for i in range(len(G)-1)]\n",
    "    L.append(G[-1].copy())\n",
    "    return L\n",
    "\n",
    "def buildLaplacian(L): \n",
    "    out = np.zeros_like(L[0], dtype=np.float32)\n",
    "    for Li in L: out += Li\n",
    "    return np.clip(out, 0.0, 1.0)\n",
    "\n",
    "def prepMask(m, like_img):\n",
    "    m = imgprocess(m)\n",
    "    if m.ndim == 3 and m.shape[2] == 3:\n",
    "        m = 0.2126*m[...,0] + 0.7152*m[...,1] + 0.0722*m[...,2]\n",
    "    if like_img.ndim == 3:\n",
    "        m = m[..., None]   # HxW -> HxWx1\n",
    "    return np.clip(m, 0.0, 1.0)\n",
    "\n",
    "def multiresBlend(A, B, blend_mask=None, levels=5, sigma_img=2.0, sigma_mask=8.0):\n",
    "    A = imgprocess(A); B = imgprocess(B)\n",
    "    A, B = samesizer(A, B)\n",
    "\n",
    "    if blend_mask is None:\n",
    "        H, W = A.shape[:2]\n",
    "        blend_mask = np.zeros((H,W), np.float32); blend_mask[:, :W//2] = 1.0\n",
    "\n",
    "    GA, GB = gaussianStack(A, levels, sigma_img), gaussianStack(B, levels, sigma_img)\n",
    "    LA, LB = laplacianStack(GA), laplacianStack(GB)\n",
    "\n",
    "    # base mask level\n",
    "    M0 = prepMask(blend_mask, A) \n",
    "    GM = [M0]\n",
    "\n",
    "    # smooth mask per level; IMPORTANT TO MAKE SURE Channel axis exists for color images otherwise wont stack properly\n",
    "    for _ in range(1, levels):\n",
    "        Mi = cv2.GaussianBlur(GM[-1], (0,0), sigmaX=sigma_mask, sigmaY=sigma_mask,\n",
    "                              borderType=cv2.BORDER_REFLECT)\n",
    "        if A.ndim == 3 and Mi.ndim == 2:   # OpenCV dropped the channel axis...pls do better\n",
    "            Mi = Mi[..., None]             # make it HxWx1 so it broadcasts to HxWx3\n",
    "        GM.append(Mi)\n",
    "\n",
    "    Lblend = []\n",
    "    for i in range(levels):\n",
    "        Mi = GM[i]\n",
    "        if LA[i].ndim == 3 and Mi.ndim == 2:\n",
    "            Mi = Mi[..., None]\n",
    "        Lblend.append(Mi * LA[i] + (1.0 - Mi) * LB[i])\n",
    "\n",
    "    blended = buildLaplacian(Lblend)\n",
    "    return blended, (GA, GB, LA, LB, GM, Lblend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa3af358",
   "metadata": {},
   "outputs": [],
   "source": [
    "appl  = \"media/lemon_cropped.jpg\"\n",
    "oran = \"media/moon_cropped.jpg\"\n",
    "\n",
    "apple  = cv2.cvtColor(cv2.imread(appl,  cv2.IMREAD_COLOR), cv2.COLOR_BGR2RGB)\n",
    "orange = cv2.cvtColor(cv2.imread(oran, cv2.IMREAD_COLOR), cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bafaa6cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H, W = apple.shape[:2]\n",
    "blend_mask = np.zeros((H, W), np.float32)\n",
    "blend_mask[:, :W//2] = 1.0\n",
    "\n",
    "#for 5 pyramid levels, changing sigma levels affects how smooth the transition is\n",
    "blended, (GA, GB, LA, LB, GM, Lblend) = multiresBlend(apple, orange, blend_mask=blend_mask, levels=5, sigma_img=2, sigma_mask=20)\n",
    "\n",
    "plt.figure(figsize=(12,10))\n",
    "plt.subplot(1,3,1); plt.imshow(apple);   plt.title(\"Lemon\");  plt.axis(\"off\")\n",
    "plt.subplot(1,3,2); plt.imshow(orange);  plt.title(\"Moon\"); plt.axis(\"off\")\n",
    "plt.subplot(1,3,3); plt.imshow(blended); plt.title(\"Lemoon\"); plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "output = (blended*255).astype(np.uint8)\n",
    "cv2.imwrite(\"oraple.png\", cv2.cvtColor(output, cv2.COLOR_RGB2BGR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b28db980",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for visualising and recreating fig3, rows of high low and medium frequencies for each of the 3 images\n",
    "def channelalign(M, like_img):\n",
    "    return M[..., None] if (like_img.ndim == 3 and M.ndim == 2) else M\n",
    "\n",
    "def normalise(x):\n",
    "    x = x.astype(np.float32)\n",
    "    mn, mx = x.min(), x.max()\n",
    "    return np.zeros_like(x) if mx <= mn else (x - mn) / (mx - mn)\n",
    "\n",
    "\n",
    "def laplaceCenter(x):\n",
    "    a = np.max(np.abs(x).astype(np.float32))\n",
    "    y = 0.5 + (x / (2*a + 1e-8))\n",
    "    return np.clip(y, 0, 1)\n",
    "\n",
    "def show(ax, img, title=\"\"):\n",
    "    im = np.squeeze(img)\n",
    "    if im.ndim == 2 or (im.ndim == 3 and im.shape[2] == 1):\n",
    "        ax.imshow(im, cmap=\"gray\", vmin=0, vmax=1)\n",
    "    else:\n",
    "        ax.imshow(im)\n",
    "    ax.set_title(title); ax.axis(\"off\")\n",
    "\n",
    "def orapleLevel(LA, LB, GM, GA, GB, blended, picks=None):\n",
    "    L = len(GA)\n",
    "    if picks is None:\n",
    "        picks = (0, L//2, L-1)   # high, mid, low frequencies\n",
    "    rows = len(picks) + 1\n",
    "    fig, axs = plt.subplots(rows, 3, figsize=(9, 3*rows))\n",
    "\n",
    "    labels = [\"high\", \"medium\", \"low\"]\n",
    "    for r, i in enumerate(picks):\n",
    "        Mi = channelalign(GM[i], LA[i])\n",
    "        left  = Mi * LA[i]\n",
    "        right = (1.0 - Mi) * LB[i]\n",
    "        both  = left + right\n",
    "        tag = labels[r] if r < len(labels) else f\"lvl {i}\"\n",
    "        show(axs[r, 0], laplaceCenter(left),f\"({tag}) Lemon (L{i})\")\n",
    "        show(axs[r, 1], laplaceCenter(right),f\"({tag}) Moon (L{i})\")\n",
    "        show(axs[r, 2], laplaceCenter(both),f\"({tag}) Lemoon (L{i})\")\n",
    "\n",
    "    #cuz dont want black line seam\n",
    "    Mcoarse = channelalign(GM[-1], GA[0])\n",
    "    show(axs[-1, 0], normalise(Mcoarse * GA[0]), \"Apple\")\n",
    "    show(axs[-1, 1], normalise((1.0-Mcoarse) * GB[0]), \"Orange\")\n",
    "    show(axs[-1, 2], normalise(blended),\"Full Oraple\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0649f70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "orapleLevel(LA, LB, GM, GA, GB, blended, picks=(0,2,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001ee27f",
   "metadata": {},
   "source": [
    "Part 2.4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f9c231ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "banan = \"media/banana.jpg\"\n",
    "dolph = \"media/dolphinfixx.png\"\n",
    "\n",
    "banana  = cv2.cvtColor(cv2.imread(banan,  cv2.IMREAD_COLOR), cv2.COLOR_BGR2RGB)\n",
    "dolphin = cv2.cvtColor(cv2.imread(dolph, cv2.IMREAD_COLOR), cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4b1606fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = cv2.imread(\"media/mask2.jpg\", cv2.IMREAD_GRAYSCALE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "047b5410",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, m = cv2.threshold(m, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "kernel = np.ones((3,3), np.uint8)\n",
    "m = cv2.morphologyEx(m, cv2.MORPH_CLOSE, kernel, iterations=1)\n",
    "m = cv2.erode(m, kernel, iterations=2) \n",
    "m = cv2.GaussianBlur(m, (0,0), 1.5)\n",
    "\n",
    "# 4) Convert to [0,1] and apply an S-curve so interior is very opaque\n",
    "alpha = (m.astype(np.float32) / 255.0)\n",
    "# S-curve: steeper transition, more opaque interior; tune k smaller -> sharper edge\n",
    "k = 0.08\n",
    "alpha = 1.0 / (1.0 + np.exp(-(alpha - 0.5)/k))\n",
    "alpha = np.clip(alpha, 0.0, 1.0)\n",
    "\n",
    "mask = alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "de4fa5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "blended, (GA, GB, LA, LB, GM, Lb) = multiresBlend(dolphin, banana,blend_mask=mask,levels=6,sigma_img=2.3,sigma_mask=3.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e5f462",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-26 17:18:29.845 python[11594:660513] +[CATransaction synchronize] called within transaction\n"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(12,4))\n",
    "plt.imshow(blended);       \n",
    "plt.title(\"Dolphana\"); plt.axis(\"off\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
